!nvcc --version

!pip install git+https://github.com/andreinechaev/nvcc4jupyter.git
%load_ext nvcc_plugin

%%cu

#include<iostream>
#include<cstdlib>
#include<cmath>

using namespace std;
__global__ void matrixMul(int *a, int *b, int *c, int n){
    int row = threadIdx.y+blockDim.y*blockIdx.y;
    int col = threadIdx.x+blockDim.x*blockIdx.x;

    int sum = 0;
    if(row<n && col<n)
    for(int j=0;j<n;j++){
        sum=sum+a[row*n+j]*b[j*n+col];
    }
    c[n*row+col]=sum;
}

int main(){
    int *a,*b,*c;
    int *a_dev,*b_dev,*c_dev;
    int n = 4;
    a=new int[n*n];
    b=new int[n*n];
    c=new int[n*n];

    int *d=new int[n*n];
    int size = n*n*sizeof(int);

    cudaMalloc(&a_dev, size);
    cudaMalloc(&b_dev, size);
    cudaMalloc(&c_dev, size);

    for(int i=0; i<n*n; i++){
        a[i]=2;
        b[i]=1;
    }

    cudaEvent_t start, end;
    cudaEventCreate(&start);
    cudaEventCreate(&end);

    cudaMemcpy(a_dev, a, size, cudaMemcpyHostToDevice);
    cudaMemcpy(b_dev, b, size, cudaMemcpyHostToDevice);

    dim3 threadsPerBlock(n, n);
    dim3 blocksPerGrid(1,1);

    cudaEventRecord(start);
    matrixMul<<<blocksPerGrid, threadsPerBlock>>>(a_dev, b_dev, c_dev, n);
    cudaEventRecord(end);

    cudaEventSynchronize(end);

    float time=0.0;
    cudaEventElapsedTime(&time, start, end);
    cudaMemcpy(c, c_dev, size, cudaMemcpyDeviceToHost);

    int sum=0;
    for(int row=0;row<n;row++){
        for(int col=0;col<n;col++){
            sum=0;
            for(int k=0;k<n; k++){
                sum=sum+a[row*n+k]*b[k*n+col];
                d[row*n+col]=sum;
            }
        }
    }

    for(int i=0;i<n*n;i++){
        printf("%d", d[i]);
        if(i%n==3){
            cout<<endl;
        }
    }
}
